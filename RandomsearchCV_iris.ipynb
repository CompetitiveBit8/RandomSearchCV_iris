{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b4cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d10391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_width  Petal_Length  Petal_width           Class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris.data')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e75c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :4]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4dacb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "81752b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "50b67f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ff0f340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "732cc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "48159ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "09c687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    RS = RandomizedSearchCV(\n",
    "    \n",
    "    estimator= RandomForestClassifier(),\n",
    "    \n",
    "    param_distributions={\n",
    "        'n_estimators': [20, 35, 40],\n",
    "        'max_depth': [x for x in np.arange(2, 10, 2)],\n",
    "        'max_features': ['sqrt', 'log2', 0.2],\n",
    "        'min_samples_leaf': [x for x in np.arange(2, 9, 2)],\n",
    "        'min_samples_split': [6, 8, 9]\n",
    "        },\n",
    "    \n",
    "    n_iter=40,\n",
    "    \n",
    "    scoring= {'r2_score':make_scorer(precision_score, average='micro'),\n",
    "              'recall_score':make_scorer(recall_score, average='micro'),\n",
    "              'accuracy_score': make_scorer(accuracy_score),\n",
    "             },\n",
    "    \n",
    "    refit='accuracy_score',\n",
    "    cv=4,\n",
    "    random_state=50,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7b27ac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-48 {color: black;}#sk-container-id-48 pre{padding: 0;}#sk-container-id-48 div.sk-toggleable {background-color: white;}#sk-container-id-48 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-48 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-48 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-48 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-48 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-48 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-48 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-48 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-48 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-48 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-48 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-48 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-48 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-48 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-48 div.sk-item {position: relative;z-index: 1;}#sk-container-id-48 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-48 div.sk-item::before, #sk-container-id-48 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-48 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-48 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-48 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-48 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-48 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-48 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-48 div.sk-label-container {text-align: center;}#sk-container-id-48 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-48 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-48\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=40,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [2, 4, 6, 8],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 0.2],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [6, 8, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [20, 35, 40]},\n",
       "                   random_state=50, refit=&#x27;accuracy_score&#x27;,\n",
       "                   scoring={&#x27;accuracy_score&#x27;: make_scorer(accuracy_score),\n",
       "                            &#x27;r2_score&#x27;: make_scorer(precision_score, average=micro),\n",
       "                            &#x27;recall_score&#x27;: make_scorer(recall_score, average=micro)},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=40,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [2, 4, 6, 8],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 0.2],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [6, 8, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [20, 35, 40]},\n",
       "                   random_state=50, refit=&#x27;accuracy_score&#x27;,\n",
       "                   scoring={&#x27;accuracy_score&#x27;: make_scorer(accuracy_score),\n",
       "                            &#x27;r2_score&#x27;: make_scorer(precision_score, average=micro),\n",
       "                            &#x27;recall_score&#x27;: make_scorer(recall_score, average=micro)},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=40,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 4, 6, 8],\n",
       "                                        'max_features': ['sqrt', 'log2', 0.2],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8],\n",
       "                                        'min_samples_split': [6, 8, 9],\n",
       "                                        'n_estimators': [20, 35, 40]},\n",
       "                   random_state=50, refit='accuracy_score',\n",
       "                   scoring={'accuracy_score': make_scorer(accuracy_score),\n",
       "                            'r2_score': make_scorer(precision_score, average=micro),\n",
       "                            'recall_score': make_scorer(recall_score, average=micro)},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3d38899d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-49 {color: black;}#sk-container-id-49 pre{padding: 0;}#sk-container-id-49 div.sk-toggleable {background-color: white;}#sk-container-id-49 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-49 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-49 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-49 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-49 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-49 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-49 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-49 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-49 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-49 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-49 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-49 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-49 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-49 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-49 div.sk-item {position: relative;z-index: 1;}#sk-container-id-49 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-49 div.sk-item::before, #sk-container-id-49 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-49 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-49 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-49 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-49 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-49 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-49 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-49 div.sk-label-container {text-align: center;}#sk-container-id-49 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-49 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-49\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=4, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=8, n_estimators=35)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" checked><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=8, n_estimators=35)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=4, max_features='log2', min_samples_leaf=2,\n",
       "                       min_samples_split=8, n_estimators=35)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8e9a2038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = RS.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ca97e163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>std_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>split0_test_accuracy_score</th>\n",
       "      <th>split1_test_accuracy_score</th>\n",
       "      <th>split2_test_accuracy_score</th>\n",
       "      <th>split3_test_accuracy_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>std_test_accuracy_score</th>\n",
       "      <th>rank_test_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109724</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>33</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108906</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.124361</td>\n",
       "      <td>31</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.124361</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055496</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>26</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103784</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.120039</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.120039</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055587</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.175419</td>\n",
       "      <td>38</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.175419</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.090818</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>0.044419</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>0.044419</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.104416</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.016833</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.067409</td>\n",
       "      <td>24</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.067409</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.053428</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>35</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055629</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.013612</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>10</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.091334</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.015751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.102937</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.080233</td>\n",
       "      <td>37</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.080233</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.053946</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.089906</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.103626</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>10</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.091157</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.178795</td>\n",
       "      <td>29</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.178795</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.021045</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.060928</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.073035</td>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.112496</td>\n",
       "      <td>23</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.112496</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.114432</td>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.113356</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.017234</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.118451</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.118451</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.119871</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>0.019582</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575893</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>30</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.575893</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.059004</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.014791</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>21</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.059106</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>33</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.014528</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.163907</td>\n",
       "      <td>39</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.163907</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.109064</td>\n",
       "      <td>0.006569</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.108791</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.056163</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.090488</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0.051291</td>\n",
       "      <td>27</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0.051291</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.052361</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.013696</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.053449</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 6, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433036</td>\n",
       "      <td>0.110350</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.433036</td>\n",
       "      <td>0.110350</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.089648</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.091332</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.090107</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.015460</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.093111</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>35</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.089815</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 35, 'min_samples_split': 8, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.072947</td>\n",
       "      <td>28</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.072947</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 40, 'min_samples_split': 9, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933036</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.109724      0.003299         0.017265        0.000363   \n",
       "1        0.108906      0.003170         0.017530        0.000649   \n",
       "2        0.055496      0.002186         0.013832        0.000443   \n",
       "3        0.103784      0.002742         0.016687        0.000216   \n",
       "4        0.055587      0.003763         0.013918        0.000282   \n",
       "5        0.090818      0.001440         0.015906        0.000384   \n",
       "6        0.104416      0.004318         0.016833        0.000625   \n",
       "7        0.053428      0.001107         0.013929        0.000210   \n",
       "8        0.055629      0.002342         0.013612        0.000092   \n",
       "9        0.091334      0.000789         0.015751        0.000277   \n",
       "10       0.102937      0.001835         0.016410        0.000224   \n",
       "11       0.053946      0.000668         0.013868        0.000163   \n",
       "12       0.089906      0.001590         0.015472        0.000204   \n",
       "13       0.103626      0.002266         0.016450        0.000073   \n",
       "14       0.091157      0.001559         0.016344        0.000353   \n",
       "15       0.056882      0.004894         0.021045        0.009058   \n",
       "16       0.060928      0.007622         0.017117        0.003673   \n",
       "17       0.073035      0.030222         0.017268        0.005830   \n",
       "18       0.107160      0.001530         0.016529        0.000116   \n",
       "19       0.114432      0.007629         0.020287        0.002513   \n",
       "20       0.113356      0.012811         0.017234        0.001743   \n",
       "21       0.119871      0.026376         0.019582        0.002929   \n",
       "22       0.059004      0.003339         0.014791        0.000409   \n",
       "23       0.059106      0.003603         0.014654        0.000707   \n",
       "24       0.068333      0.010058         0.014528        0.000706   \n",
       "25       0.109064      0.006569         0.016417        0.000443   \n",
       "26       0.108791      0.008792         0.016771        0.000750   \n",
       "27       0.107650      0.004033         0.016268        0.000138   \n",
       "28       0.056163      0.003062         0.013633        0.000132   \n",
       "29       0.089221      0.000346         0.015733        0.000300   \n",
       "30       0.090488      0.001557         0.015530        0.000154   \n",
       "31       0.052361      0.000664         0.013696        0.000158   \n",
       "32       0.053449      0.000993         0.013656        0.000360   \n",
       "33       0.089648      0.001018         0.015492        0.000072   \n",
       "34       0.088745      0.000621         0.015654        0.000333   \n",
       "35       0.091332      0.002080         0.015289        0.000038   \n",
       "36       0.090107      0.002311         0.015460        0.000136   \n",
       "37       0.093111      0.012084         0.014314        0.002584   \n",
       "38       0.089815      0.002050         0.015577        0.000213   \n",
       "39       0.097038      0.005073         0.012222        0.002773   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                  40                       6                      8   \n",
       "1                  40                       8                      8   \n",
       "2                  20                       9                      6   \n",
       "3                  40                       9                      6   \n",
       "4                  20                       9                      8   \n",
       "5                  35                       6                      8   \n",
       "6                  40                       9                      6   \n",
       "7                  20                       8                      8   \n",
       "8                  20                       8                      4   \n",
       "9                  35                       8                      2   \n",
       "10                 40                       9                      8   \n",
       "11                 20                       8                      2   \n",
       "12                 35                       6                      2   \n",
       "13                 40                       9                      2   \n",
       "14                 35                       8                      8   \n",
       "15                 20                       6                      6   \n",
       "16                 20                       8                      4   \n",
       "17                 20                       6                      6   \n",
       "18                 40                       6                      2   \n",
       "19                 35                       6                      4   \n",
       "20                 35                       9                      4   \n",
       "21                 35                       9                      8   \n",
       "22                 20                       6                      6   \n",
       "23                 20                       9                      8   \n",
       "24                 20                       8                      8   \n",
       "25                 40                       9                      2   \n",
       "26                 40                       9                      2   \n",
       "27                 40                       8                      4   \n",
       "28                 20                       6                      4   \n",
       "29                 35                       9                      2   \n",
       "30                 35                       8                      8   \n",
       "31                 20                       9                      2   \n",
       "32                 20                       6                      8   \n",
       "33                 35                       9                      4   \n",
       "34                 35                       9                      6   \n",
       "35                 35                       8                      4   \n",
       "36                 35                       9                      2   \n",
       "37                 40                       8                      8   \n",
       "38                 35                       8                      8   \n",
       "39                 40                       9                      6   \n",
       "\n",
       "   param_max_features param_max_depth  \\\n",
       "0                sqrt               2   \n",
       "1                 0.2               8   \n",
       "2                sqrt               2   \n",
       "3                log2               8   \n",
       "4                log2               4   \n",
       "5                sqrt               6   \n",
       "6                 0.2               2   \n",
       "7                log2               8   \n",
       "8                sqrt               8   \n",
       "9                log2               4   \n",
       "10               log2               4   \n",
       "11               log2               8   \n",
       "12               log2               6   \n",
       "13                0.2               6   \n",
       "14               log2               6   \n",
       "15               log2               4   \n",
       "16               sqrt               4   \n",
       "17               sqrt               6   \n",
       "18               log2               8   \n",
       "19               sqrt               6   \n",
       "20                0.2               2   \n",
       "21               sqrt               2   \n",
       "22                0.2               4   \n",
       "23                0.2               4   \n",
       "24               log2               6   \n",
       "25               sqrt               4   \n",
       "26                0.2               4   \n",
       "27               log2               4   \n",
       "28               log2               4   \n",
       "29               log2               4   \n",
       "30               log2               8   \n",
       "31               sqrt               4   \n",
       "32                0.2               2   \n",
       "33               sqrt               4   \n",
       "34                0.2               2   \n",
       "35               sqrt               4   \n",
       "36               sqrt               4   \n",
       "37               sqrt               6   \n",
       "38               log2               2   \n",
       "39               sqrt               6   \n",
       "\n",
       "                                               params  ...  \\\n",
       "0   {'n_estimators': 40, 'min_samples_split': 6, '...  ...   \n",
       "1   {'n_estimators': 40, 'min_samples_split': 8, '...  ...   \n",
       "2   {'n_estimators': 20, 'min_samples_split': 9, '...  ...   \n",
       "3   {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "4   {'n_estimators': 20, 'min_samples_split': 9, '...  ...   \n",
       "5   {'n_estimators': 35, 'min_samples_split': 6, '...  ...   \n",
       "6   {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "7   {'n_estimators': 20, 'min_samples_split': 8, '...  ...   \n",
       "8   {'n_estimators': 20, 'min_samples_split': 8, '...  ...   \n",
       "9   {'n_estimators': 35, 'min_samples_split': 8, '...  ...   \n",
       "10  {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "11  {'n_estimators': 20, 'min_samples_split': 8, '...  ...   \n",
       "12  {'n_estimators': 35, 'min_samples_split': 6, '...  ...   \n",
       "13  {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "14  {'n_estimators': 35, 'min_samples_split': 8, '...  ...   \n",
       "15  {'n_estimators': 20, 'min_samples_split': 6, '...  ...   \n",
       "16  {'n_estimators': 20, 'min_samples_split': 8, '...  ...   \n",
       "17  {'n_estimators': 20, 'min_samples_split': 6, '...  ...   \n",
       "18  {'n_estimators': 40, 'min_samples_split': 6, '...  ...   \n",
       "19  {'n_estimators': 35, 'min_samples_split': 6, '...  ...   \n",
       "20  {'n_estimators': 35, 'min_samples_split': 9, '...  ...   \n",
       "21  {'n_estimators': 35, 'min_samples_split': 9, '...  ...   \n",
       "22  {'n_estimators': 20, 'min_samples_split': 6, '...  ...   \n",
       "23  {'n_estimators': 20, 'min_samples_split': 9, '...  ...   \n",
       "24  {'n_estimators': 20, 'min_samples_split': 8, '...  ...   \n",
       "25  {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "26  {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "27  {'n_estimators': 40, 'min_samples_split': 8, '...  ...   \n",
       "28  {'n_estimators': 20, 'min_samples_split': 6, '...  ...   \n",
       "29  {'n_estimators': 35, 'min_samples_split': 9, '...  ...   \n",
       "30  {'n_estimators': 35, 'min_samples_split': 8, '...  ...   \n",
       "31  {'n_estimators': 20, 'min_samples_split': 9, '...  ...   \n",
       "32  {'n_estimators': 20, 'min_samples_split': 6, '...  ...   \n",
       "33  {'n_estimators': 35, 'min_samples_split': 9, '...  ...   \n",
       "34  {'n_estimators': 35, 'min_samples_split': 9, '...  ...   \n",
       "35  {'n_estimators': 35, 'min_samples_split': 8, '...  ...   \n",
       "36  {'n_estimators': 35, 'min_samples_split': 9, '...  ...   \n",
       "37  {'n_estimators': 40, 'min_samples_split': 8, '...  ...   \n",
       "38  {'n_estimators': 35, 'min_samples_split': 8, '...  ...   \n",
       "39  {'n_estimators': 40, 'min_samples_split': 9, '...  ...   \n",
       "\n",
       "    mean_test_recall_score  std_test_recall_score  rank_test_recall_score  \\\n",
       "0                 0.535714               0.095331                      33   \n",
       "1                 0.571429               0.124361                      31   \n",
       "2                 0.758929               0.126584                      26   \n",
       "3                 0.825893               0.120039                      25   \n",
       "4                 0.500000               0.175419                      38   \n",
       "5                 0.566964               0.044419                      32   \n",
       "6                 0.830357               0.067409                      24   \n",
       "7                 0.508929               0.143136                      35   \n",
       "8                 0.968750               0.054127                      10   \n",
       "9                 1.000000               0.000000                       1   \n",
       "10                0.504464               0.080233                      37   \n",
       "11                1.000000               0.000000                       1   \n",
       "12                1.000000               0.000000                       1   \n",
       "13                0.968750               0.054127                      10   \n",
       "14                0.598214               0.178795                      29   \n",
       "15                0.933036               0.067261                      15   \n",
       "16                0.928571               0.123718                      19   \n",
       "17                0.834821               0.112496                      23   \n",
       "18                1.000000               0.000000                       1   \n",
       "19                1.000000               0.000000                       1   \n",
       "20                0.892857               0.118451                      20   \n",
       "21                0.575893               0.145278                      30   \n",
       "22                0.866071               0.008929                      21   \n",
       "23                0.535714               0.095331                      33   \n",
       "24                0.437500               0.163907                      39   \n",
       "25                1.000000               0.000000                       1   \n",
       "26                0.933036               0.067261                      15   \n",
       "27                0.964286               0.061859                      12   \n",
       "28                1.000000               0.000000                       1   \n",
       "29                0.964286               0.061859                      12   \n",
       "30                0.633929               0.051291                      27   \n",
       "31                0.933036               0.067261                      15   \n",
       "32                0.433036               0.110350                      40   \n",
       "33                1.000000               0.000000                       1   \n",
       "34                0.861607               0.101311                      22   \n",
       "35                1.000000               0.000000                       1   \n",
       "36                0.964286               0.061859                      12   \n",
       "37                0.508929               0.143136                      35   \n",
       "38                0.629464               0.072947                      28   \n",
       "39                0.933036               0.067261                      15   \n",
       "\n",
       "    split0_test_accuracy_score  split1_test_accuracy_score  \\\n",
       "0                        0.375                       0.625   \n",
       "1                        0.375                       0.625   \n",
       "2                        0.875                       0.875   \n",
       "3                        1.000                       0.875   \n",
       "4                        0.625                       0.375   \n",
       "5                        0.500                       0.625   \n",
       "6                        0.875                       0.875   \n",
       "7                        0.375                       0.375   \n",
       "8                        0.875                       1.000   \n",
       "9                        1.000                       1.000   \n",
       "10                       0.500                       0.375   \n",
       "11                       1.000                       1.000   \n",
       "12                       1.000                       1.000   \n",
       "13                       0.875                       1.000   \n",
       "14                       0.875                       0.375   \n",
       "15                       1.000                       0.875   \n",
       "16                       1.000                       1.000   \n",
       "17                       0.875                       0.750   \n",
       "18                       1.000                       1.000   \n",
       "19                       1.000                       1.000   \n",
       "20                       1.000                       1.000   \n",
       "21                       0.500                       0.375   \n",
       "22                       0.875                       0.875   \n",
       "23                       0.625                       0.375   \n",
       "24                       0.375                       0.375   \n",
       "25                       1.000                       1.000   \n",
       "26                       0.875                       1.000   \n",
       "27                       1.000                       1.000   \n",
       "28                       1.000                       1.000   \n",
       "29                       1.000                       1.000   \n",
       "30                       0.625                       0.625   \n",
       "31                       0.875                       1.000   \n",
       "32                       0.500                       0.375   \n",
       "33                       1.000                       1.000   \n",
       "34                       1.000                       0.875   \n",
       "35                       1.000                       1.000   \n",
       "36                       1.000                       1.000   \n",
       "37                       0.375                       0.375   \n",
       "38                       0.750                       0.625   \n",
       "39                       1.000                       0.875   \n",
       "\n",
       "    split2_test_accuracy_score  split3_test_accuracy_score  \\\n",
       "0                     0.571429                    0.571429   \n",
       "1                     0.714286                    0.571429   \n",
       "2                     0.714286                    0.571429   \n",
       "3                     0.714286                    0.714286   \n",
       "4                     0.714286                    0.285714   \n",
       "5                     0.571429                    0.571429   \n",
       "6                     0.857143                    0.714286   \n",
       "7                     0.571429                    0.714286   \n",
       "8                     1.000000                    1.000000   \n",
       "9                     1.000000                    1.000000   \n",
       "10                    0.571429                    0.571429   \n",
       "11                    1.000000                    1.000000   \n",
       "12                    1.000000                    1.000000   \n",
       "13                    1.000000                    1.000000   \n",
       "14                    0.571429                    0.571429   \n",
       "15                    0.857143                    1.000000   \n",
       "16                    1.000000                    0.714286   \n",
       "17                    1.000000                    0.714286   \n",
       "18                    1.000000                    1.000000   \n",
       "19                    1.000000                    1.000000   \n",
       "20                    0.857143                    0.714286   \n",
       "21                    0.714286                    0.714286   \n",
       "22                    0.857143                    0.857143   \n",
       "23                    0.571429                    0.571429   \n",
       "24                    0.714286                    0.285714   \n",
       "25                    1.000000                    1.000000   \n",
       "26                    0.857143                    1.000000   \n",
       "27                    1.000000                    0.857143   \n",
       "28                    1.000000                    1.000000   \n",
       "29                    0.857143                    1.000000   \n",
       "30                    0.714286                    0.571429   \n",
       "31                    0.857143                    1.000000   \n",
       "32                    0.571429                    0.285714   \n",
       "33                    1.000000                    1.000000   \n",
       "34                    0.857143                    0.714286   \n",
       "35                    1.000000                    1.000000   \n",
       "36                    0.857143                    1.000000   \n",
       "37                    0.714286                    0.571429   \n",
       "38                    0.571429                    0.571429   \n",
       "39                    0.857143                    1.000000   \n",
       "\n",
       "    mean_test_accuracy_score  std_test_accuracy_score  \\\n",
       "0                   0.535714                 0.095331   \n",
       "1                   0.571429                 0.124361   \n",
       "2                   0.758929                 0.126584   \n",
       "3                   0.825893                 0.120039   \n",
       "4                   0.500000                 0.175419   \n",
       "5                   0.566964                 0.044419   \n",
       "6                   0.830357                 0.067409   \n",
       "7                   0.508929                 0.143136   \n",
       "8                   0.968750                 0.054127   \n",
       "9                   1.000000                 0.000000   \n",
       "10                  0.504464                 0.080233   \n",
       "11                  1.000000                 0.000000   \n",
       "12                  1.000000                 0.000000   \n",
       "13                  0.968750                 0.054127   \n",
       "14                  0.598214                 0.178795   \n",
       "15                  0.933036                 0.067261   \n",
       "16                  0.928571                 0.123718   \n",
       "17                  0.834821                 0.112496   \n",
       "18                  1.000000                 0.000000   \n",
       "19                  1.000000                 0.000000   \n",
       "20                  0.892857                 0.118451   \n",
       "21                  0.575893                 0.145278   \n",
       "22                  0.866071                 0.008929   \n",
       "23                  0.535714                 0.095331   \n",
       "24                  0.437500                 0.163907   \n",
       "25                  1.000000                 0.000000   \n",
       "26                  0.933036                 0.067261   \n",
       "27                  0.964286                 0.061859   \n",
       "28                  1.000000                 0.000000   \n",
       "29                  0.964286                 0.061859   \n",
       "30                  0.633929                 0.051291   \n",
       "31                  0.933036                 0.067261   \n",
       "32                  0.433036                 0.110350   \n",
       "33                  1.000000                 0.000000   \n",
       "34                  0.861607                 0.101311   \n",
       "35                  1.000000                 0.000000   \n",
       "36                  0.964286                 0.061859   \n",
       "37                  0.508929                 0.143136   \n",
       "38                  0.629464                 0.072947   \n",
       "39                  0.933036                 0.067261   \n",
       "\n",
       "    rank_test_accuracy_score  \n",
       "0                         33  \n",
       "1                         31  \n",
       "2                         26  \n",
       "3                         25  \n",
       "4                         38  \n",
       "5                         32  \n",
       "6                         24  \n",
       "7                         35  \n",
       "8                         10  \n",
       "9                          1  \n",
       "10                        37  \n",
       "11                         1  \n",
       "12                         1  \n",
       "13                        10  \n",
       "14                        29  \n",
       "15                        15  \n",
       "16                        19  \n",
       "17                        23  \n",
       "18                         1  \n",
       "19                         1  \n",
       "20                        20  \n",
       "21                        30  \n",
       "22                        21  \n",
       "23                        33  \n",
       "24                        39  \n",
       "25                         1  \n",
       "26                        15  \n",
       "27                        12  \n",
       "28                         1  \n",
       "29                        12  \n",
       "30                        27  \n",
       "31                        15  \n",
       "32                        40  \n",
       "33                         1  \n",
       "34                        22  \n",
       "35                         1  \n",
       "36                        12  \n",
       "37                        35  \n",
       "38                        28  \n",
       "39                        15  \n",
       "\n",
       "[40 rows x 31 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(RS.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a40a240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fa739a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [4, 5, 6], 'max_features': ['log2'], 'min_samples_leaf': [2, 4, 6], 'min_samples_split': [8, 10, 12], 'n_estimators': [35, 42, 49]}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    \n",
    "    param_grid={\n",
    "        'max_depth': [RS.best_params_['max_depth'], \n",
    "                      RS.best_params_['max_depth'] +1, \n",
    "                      RS.best_params_['max_depth'] +2],\n",
    "        \n",
    "        'max_features' : [RS.best_params_['max_features']],\n",
    "        \n",
    "        'min_samples_leaf': [RS.best_params_['min_samples_leaf'],\n",
    "                             RS.best_params_['min_samples_leaf'] +2,\n",
    "                             RS.best_params_['min_samples_leaf'] +4],\n",
    "        \n",
    "        'min_samples_split':[RS.best_params_['min_samples_split'],\n",
    "                             RS.best_params_['min_samples_split'] +2,\n",
    "                             RS.best_params_['min_samples_split'] +4],\n",
    "         \n",
    "        'n_estimators': [RS.best_params_['n_estimators'],\n",
    "                         RS.best_params_['n_estimators'] +7,\n",
    "                         RS.best_params_['n_estimators'] +14]\n",
    "    }, \n",
    "     \n",
    "    refit='accuracy_score',\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "print(GS.param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd83374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 81 candidates, totalling 324 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-50 {color: black;}#sk-container-id-50 pre{padding: 0;}#sk-container-id-50 div.sk-toggleable {background-color: white;}#sk-container-id-50 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-50 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-50 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-50 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-50 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-50 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-50 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-50 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-50 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-50 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-50 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-50 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-50 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-50 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-50 div.sk-item {position: relative;z-index: 1;}#sk-container-id-50 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-50 div.sk-item::before, #sk-container-id-50 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-50 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-50 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-50 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-50 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-50 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-50 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-50 div.sk-label-container {text-align: center;}#sk-container-id-50 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-50 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-50\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 5, 6], &#x27;max_features&#x27;: [&#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 4, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [8, 10, 12],\n",
       "                         &#x27;n_estimators&#x27;: [35, 42, 49]},\n",
       "             refit=&#x27;accuracy_score&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 5, 6], &#x27;max_features&#x27;: [&#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 4, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [8, 10, 12],\n",
       "                         &#x27;n_estimators&#x27;: [35, 42, 49]},\n",
       "             refit=&#x27;accuracy_score&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [4, 5, 6], 'max_features': ['log2'],\n",
       "                         'min_samples_leaf': [2, 4, 6],\n",
       "                         'min_samples_split': [8, 10, 12],\n",
       "                         'n_estimators': [35, 42, 49]},\n",
       "             refit='accuracy_score', verbose=1)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fc9c51dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120605</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134842</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097330</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112628</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.009816</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.142337</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.014217</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.152022</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.103542</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.136461</td>\n",
       "      <td>0.020739</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.129445</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.099046      0.001373         0.009270        0.000134   \n",
       "1        0.120605      0.005659         0.013326        0.005796   \n",
       "2        0.134842      0.005637         0.011447        0.000716   \n",
       "3        0.097330      0.003322         0.009183        0.000171   \n",
       "4        0.112628      0.003347         0.009816        0.000188   \n",
       "..            ...           ...              ...             ...   \n",
       "76       0.142337      0.034266         0.014217        0.006770   \n",
       "77       0.152022      0.022816         0.013402        0.002870   \n",
       "78       0.103542      0.011279         0.009154        0.000456   \n",
       "79       0.136461      0.020739         0.009375        0.000521   \n",
       "80       0.129445      0.014254         0.009632        0.002015   \n",
       "\n",
       "   param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "0                4               log2                      2   \n",
       "1                4               log2                      2   \n",
       "2                4               log2                      2   \n",
       "3                4               log2                      2   \n",
       "4                4               log2                      2   \n",
       "..             ...                ...                    ...   \n",
       "76               6               log2                      6   \n",
       "77               6               log2                      6   \n",
       "78               6               log2                      6   \n",
       "79               6               log2                      6   \n",
       "80               6               log2                      6   \n",
       "\n",
       "   param_min_samples_split param_n_estimators  \\\n",
       "0                        8                 35   \n",
       "1                        8                 42   \n",
       "2                        8                 49   \n",
       "3                       10                 35   \n",
       "4                       10                 42   \n",
       "..                     ...                ...   \n",
       "76                      10                 42   \n",
       "77                      10                 49   \n",
       "78                      12                 35   \n",
       "79                      12                 42   \n",
       "80                      12                 49   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 4, 'max_features': 'log2', 'min_...           0.966667   \n",
       "1   {'max_depth': 4, 'max_features': 'log2', 'min_...           0.966667   \n",
       "2   {'max_depth': 4, 'max_features': 'log2', 'min_...           0.966667   \n",
       "3   {'max_depth': 4, 'max_features': 'log2', 'min_...           0.966667   \n",
       "4   {'max_depth': 4, 'max_features': 'log2', 'min_...           0.966667   \n",
       "..                                                ...                ...   \n",
       "76  {'max_depth': 6, 'max_features': 'log2', 'min_...           0.966667   \n",
       "77  {'max_depth': 6, 'max_features': 'log2', 'min_...           0.966667   \n",
       "78  {'max_depth': 6, 'max_features': 'log2', 'min_...           0.966667   \n",
       "79  {'max_depth': 6, 'max_features': 'log2', 'min_...           0.966667   \n",
       "80  {'max_depth': 6, 'max_features': 'log2', 'min_...           0.966667   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0                 1.0           0.933333           0.866667         0.941667   \n",
       "1                 1.0           0.933333           0.866667         0.941667   \n",
       "2                 1.0           0.933333           0.866667         0.941667   \n",
       "3                 1.0           0.933333           0.866667         0.941667   \n",
       "4                 1.0           0.933333           0.866667         0.941667   \n",
       "..                ...                ...                ...              ...   \n",
       "76                1.0           0.933333           0.866667         0.941667   \n",
       "77                1.0           0.933333           0.900000         0.950000   \n",
       "78                1.0           0.933333           0.866667         0.941667   \n",
       "79                1.0           0.933333           0.866667         0.941667   \n",
       "80                1.0           0.933333           0.866667         0.941667   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.049301               15  \n",
       "1         0.049301               15  \n",
       "2         0.049301               15  \n",
       "3         0.049301               15  \n",
       "4         0.049301               15  \n",
       "..             ...              ...  \n",
       "76        0.049301               15  \n",
       "77        0.037268                2  \n",
       "78        0.049301               15  \n",
       "79        0.049301               15  \n",
       "80        0.049301               15  \n",
       "\n",
       "[81 rows x 17 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.cv_results_\n",
    "\n",
    "pd.DataFrame(GS.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2311a396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-51 {color: black;}#sk-container-id-51 pre{padding: 0;}#sk-container-id-51 div.sk-toggleable {background-color: white;}#sk-container-id-51 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-51 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-51 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-51 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-51 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-51 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-51 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-51 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-51 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-51 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-51 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-51 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-51 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-51 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-51 div.sk-item {position: relative;z-index: 1;}#sk-container-id-51 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-51 div.sk-item::before, #sk-container-id-51 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-51 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-51 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-51 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-51 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-51 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-51 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-51 div.sk-label-container {text-align: center;}#sk-container-id-51 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-51 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-51\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=12, n_estimators=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" checked><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=12, n_estimators=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features='log2', min_samples_leaf=2,\n",
       "                       min_samples_split=12, n_estimators=42)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "52b2c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "973753a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 2, 2, 1, 2, 1, 0, 1,\n",
       "       0, 2, 2, 2, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "328371aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "78bd871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7578/719381346.py:1: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=y_test, y=y_pred, data=df.iloc[120:, :4], palette='coolwarm')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=y_test, y=y_pred, data=df.iloc[120:, :4], palette='coolwarm')\n",
    "plt.ylabel('y_pred')\n",
    "plt.xlabel('y_test')\n",
    "plt.title('Comparison graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "41e965cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_width  Petal_Length  Petal_width  Class\n",
       "120           6.9          3.2           5.7          2.3      1\n",
       "121           5.6          2.8           4.9          2.0      2\n",
       "122           7.7          2.8           6.7          2.0      1\n",
       "123           6.3          2.7           4.9          1.8      1\n",
       "124           6.7          3.3           5.7          2.1      1\n",
       "125           7.2          3.2           6.0          1.8      0\n",
       "126           6.2          2.8           4.8          1.8      1\n",
       "127           6.1          3.0           4.9          1.8      1\n",
       "128           6.4          2.8           5.6          2.1      0\n",
       "129           7.2          3.0           5.8          1.6      0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.iloc[120:, :4]\n",
    "data['Class'] = y_pred\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fd6c760d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sepal_Length    30\n",
       "Sepal_width     30\n",
       "Petal_Length    30\n",
       "Petal_width     30\n",
       "Class           30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03c963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
